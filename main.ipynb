{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import math\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(filename, folder = \"csv\"): \n",
    "    \"\"\"Load the csv file, preprocess if necessary and return a dataframe\n",
    "\n",
    "    Args: \n",
    "        filename (str): Name of the file to load \n",
    "        folder (str): Name of the folder where the file is located\n",
    "\n",
    "    Returns:\n",
    "        pandas.DataFrame: Dataframe with the data from the csv file\n",
    "    \"\"\"\n",
    "    assert isinstance(filename, str), \"filename must be a string\"\n",
    "    assert isinstance(folder, str), \"folder must be a string\"\n",
    "    assert filename.endswith(\".csv\"), \"filename must be a csv file\"\n",
    "\n",
    "    # Load the data\n",
    "    if filename == \"abalone.csv\": \n",
    "        df = pd.read_csv(f\"{folder}/{filename}\", header = None)\n",
    "    elif filename == \"adult.csv\":\n",
    "        df = pd.read_csv(f\"{folder}/{filename}\", header = None, sep=\";\")\n",
    "    elif filename == \"balance-scale.csv\":\n",
    "        df = pd.read_csv(f\"{folder}/{filename}\", header = None)\n",
    "    elif filename == \"breast-cancer-wisconsin.csv\":\n",
    "        df = pd.read_csv(f\"{folder}/{filename}\", header = None, sep=\",\")\n",
    "    elif filename == \"bridges.csv\":\n",
    "        df = pd.read_csv(f\"{folder}/{filename}\", header = None, na_values=\"?\")\n",
    "    elif filename == \"chess.csv\":\n",
    "        df = pd.read_csv(f\"{folder}/{filename}\", header = None)\n",
    "    elif filename == \"echocardiogram.csv\":\n",
    "        df = pd.read_csv(f\"{folder}/{filename}\", header = None,na_values=\"?\")\n",
    "    elif filename == \"flight_1k.csv\":\n",
    "        df = pd.read_csv(f\"{folder}/{filename}\", header = None, sep=\";\",na_values='\"\"')\n",
    "        # remove the first line\n",
    "        df = df.iloc[1:]\n",
    "        # drop nan by column\n",
    "        df = df.dropna(axis=1, how='all')\n",
    "    elif filename == \"hepatitis.csv\":\n",
    "        df = pd.read_csv(f\"{folder}/{filename}\", header = None, na_values=\"?\")\n",
    "    elif filename == \"horse.csv\":\n",
    "        df = pd.read_csv(f\"{folder}/{filename}\", header = None, na_values=\"?\", sep=\";\")\n",
    "    elif filename == \"iris.csv\":\n",
    "        df = pd.read_csv(f\"{folder}/{filename}\")\n",
    "    elif filename == \"letter.csv\":\n",
    "        df = pd.read_csv(f\"{folder}/{filename}\", header = None)\n",
    "    elif filename == \"nursery.csv\":\n",
    "        df = pd.read_csv(f\"{folder}/{filename}\", header = None)\n",
    "    elif filename == \"plista_1k.csv\":\n",
    "        df = pd.read_csv(f\"{folder}/{filename}\", header = None, sep=\";\")\n",
    "    else: \n",
    "        df = pd.read_csv(f\"{folder}/{filename}\", header = None)\n",
    "\n",
    "    colnames = {i: chr(65 + i) for i in range(26)}\n",
    "    return df.rename(columns = colnames)\n",
    "df = load_data(\"bridges.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def union_inter_element(s):\n",
    "    \"\"\"Strict union of all tuple\n",
    "\n",
    "    Rule : If we have element of size 1, 2 element of size 1 are needed to create the new element\n",
    "    If we have element of size 2, we need 3 elements of size 2...\n",
    "\n",
    "    {(a,b),(b,c),(c,a)} gives us : {(a,b,c)}\n",
    "    {(a,b),(c,a)} gives us : {}\n",
    "\n",
    "    Args:\n",
    "        s (set): Set of tuple\n",
    "\n",
    "    Returns:\n",
    "        set: Union of all tuple \n",
    "\n",
    "    \"\"\"\n",
    "    if len(s) == 0:\n",
    "        return set()\n",
    "    \n",
    "    res = {}\n",
    "\n",
    "    n = len(next(iter(s))) + 1 \n",
    "    for comb in itertools.combinations(s, 2):\n",
    "        # comb 0 and comb 1 are tuple\n",
    "        a = set({i for i in comb[0]})\n",
    "        b = set({i for i in comb[1]})\n",
    "\n",
    "        u = tuple(a.union(b))\n",
    "        if len(u) == n:\n",
    "            if u not in res:\n",
    "                res[u] = 1\n",
    "            else:\n",
    "                res[u] += 1\n",
    "        max_val = max([v for k, v in res.items()], default=0)\n",
    "    return set([k for k, v in res.items() if v == max_val])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of minimals FD found : 69\n",
      "ECF -> AG\n",
      "EGC -> A\n",
      "EHF -> ABCDGI\n",
      "EGH -> ABCDFI\n",
      "EGF -> AC\n",
      "GHFD -> ABCEI\n",
      "EBFD -> ACGH\n",
      "GCFI -> AH\n",
      "EBDI -> A\n",
      "EBCH -> ADFGI\n",
      "EBCD -> A\n",
      "GFDI -> ABCEH\n",
      "ECHD -> A\n",
      "HIGCD -> A\n",
      "HIBCFD -> AG\n",
      "ECFD -> BHI\n",
      "GCFD -> B\n",
      "EGFD -> BHI\n",
      "GFAI -> CH\n",
      "EBFA -> CDGH\n",
      "EIBFD -> C\n",
      "EIBFA -> C\n",
      "HIGFA -> C\n",
      "EBCF -> DH\n",
      "HIBCGD -> F\n",
      "HIBCGA -> F\n",
      "DHIGCBA -> F\n",
      "AIBCFD -> GH\n",
      "DHIBCFA -> G\n",
      "EBF -> I\n"
     ]
    }
   ],
   "source": [
    "def latice_exploration(df, prettyPrint = True):\n",
    "    \"\"\"Explore the latice of combinations to find functionnal dependencies.\n",
    "\n",
    "    Args:\n",
    "        df (pandas.DataFrame): Dataframe with the data to explore\n",
    "        prettyPrint (bool): If True, print the result in a nice way (default: True)\n",
    "\n",
    "    Returns:\n",
    "        list: List of functionnal dependencies\n",
    "    \"\"\"\n",
    "\n",
    "    def test_fd(X, Y):\n",
    "        return df.groupby(list(X))[Y].nunique().le(1).all().all()\n",
    "    count = 0\n",
    "    rules = {}\n",
    "    for y in df.columns:\n",
    "        rules[y] = []\n",
    "        candidates = set((i,) for i in df.columns if i != y)\n",
    "        \n",
    "        while len(candidates) >= 1:\n",
    "            l = candidates.copy()\n",
    "            for candidate in l:\n",
    "                #print(candidate)\n",
    "                if test_fd(candidate, y):\n",
    "                    count += 1\n",
    "                    rules[y].append([candidate])\n",
    "                    candidates.remove(candidate)\n",
    "            \n",
    "            candidates = union_inter_element(candidates)\n",
    "\n",
    "        if len(rules[y]) == 0:\n",
    "            del rules[y]\n",
    "    if prettyPrint:\n",
    "        inverseMap = {}\n",
    "        for k, v in rules.items():\n",
    "            for i in v:\n",
    "                if tuple(i) not in inverseMap:\n",
    "                    inverseMap[tuple(i)] = [k]\n",
    "                else:\n",
    "                    inverseMap[tuple(i)].append(k)\n",
    "        print(f\"Number of minimals FD found : {count}\")\n",
    "        for k, v in inverseMap.items():\n",
    "            print(f\"{''.join(k[0])} -> {''.join(v)}\")\n",
    "            \n",
    "    else:\n",
    "        return count\n",
    "df = load_data(\"abalone.csv\")\n",
    "latice_exploration(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def latice_exploration_naÃ¯ve(df):\n",
    "    \"\"\"Explore the latice of combinations to find functionnal dependencies.\n",
    "\n",
    "    Args:\n",
    "        df (pandas.DataFrame): Dataframe with the data to explore\n",
    "    Returns:\n",
    "        list: List of functionnal dependencies\n",
    "    \"\"\"\n",
    "    def test_fd(X, Y):\n",
    "        return df.groupby(X)[Y].nunique().le(1).all().all()\n",
    "    rules = []\n",
    "    for y in df.columns:\n",
    "        for n in range(1, len(df.columns)):\n",
    "            for X in itertools.combinations(set(df.columns) - {y}, n):\n",
    "                if test_fd(list(X), y):\n",
    "                    rules.append([list(X), [y]])\n",
    "    return rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Filename | TimeOpti | TimeNaive | ResOpti | ResNaive |\n",
      "| --- | --- | --- | --- | --- |\n",
      "coucou\n",
      "| iris.csv | 0.026702404022216797 | 0.022899627685546875 | 4 | 5 |\n",
      "| letter.csv | >2000s | >2000s | 0 | 0 |\n",
      "| nursery.csv | 2.5882556438446045 | 5.732923984527588 | 0 | 1 |\n",
      "| plista_1k.csv | >2000s | >2000s | 0 | 0 |\n"
     ]
    }
   ],
   "source": [
    "filenames = [\"abalone.csv\", \"bridges.csv\", \"car.csv\", \"hepatitis.csv\", \"horse.csv\", \"iris.csv\", \"letter.csv\", \"nursery.csv\", \"plista_1k.csv\"]\n",
    "tOpti = {}\n",
    "minFD = {}\n",
    "tNaive = {}\n",
    "fd = {}\n",
    "def timeout(func, args=(), kwargs={}, timeout_duration=10, default=None):\n",
    "    import signal\n",
    "\n",
    "    class TimeoutError(Exception):\n",
    "        pass\n",
    "\n",
    "    def handler(signum, frame):\n",
    "        raise TimeoutError()\n",
    "\n",
    "    # set the timeout handler\n",
    "    signal.signal(signal.SIGALRM, handler) \n",
    "    signal.alarm(timeout_duration)\n",
    "    try:\n",
    "        result = func(*args, **kwargs)\n",
    "    except TimeoutError as exc:\n",
    "        result = default\n",
    "    finally:\n",
    "        signal.alarm(0)\n",
    "\n",
    "    return result\n",
    "import time\n",
    "print(\"| Filename | TimeOpti | TimeNaive | ResOpti | ResNaive |\")\n",
    "print(\"| --- | --- | --- | --- | --- |\")\n",
    "for filename in filenames:\n",
    "    df = load_data(filename)\n",
    "    start = time.time()\n",
    "    minFD[filename] = timeout(latice_exploration, args=(df,False), timeout_duration=2000)\n",
    "    end = time.time()\n",
    "    if minFD[filename] is None:\n",
    "        minFD[filename] = 0\n",
    "        tOpti[filename] = \">2000s\"\n",
    "    else:\n",
    "        tOpti[filename] = end - start\n",
    "    start = time.time()\n",
    "    fd[filename] = timeout(latice_exploration_naÃ¯ve, args=(df,), timeout_duration=2000)\n",
    "    end = time.time()\n",
    "    if fd[filename] is None:\n",
    "        fd[filename] = []\n",
    "        tNaive[filename] = \">2000s\"\n",
    "    else:\n",
    "        tNaive[filename] = end - start\n",
    "    print(f\"| {filename} | {tOpti[filename]} | {tNaive[filename]} | {minFD[filename]} | {len(fd[filename])} |\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you want to test on a specific dataset and see the results\n",
    "df = load_data(\"chess.csv\")\n",
    "latice_exploration(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you want to test on a specific dataset and see the results\n",
    "df = load_data(\"bridges.csv\")\n",
    "latice_exploration(df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "949777d72b0d2535278d3dc13498b2535136f6dfe0678499012e853ee9abcab1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
